{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **NYC Taxi Demand Anomaly Detection Using LSTM**\n",
        "Developed an LSTM-based classifier to detect anomalies in NYC taxi demand data. The project involved time series preprocessing, sequence modeling, and training a neural network to identify unusual demand patterns. This helped build a practical understanding of deep learning techniques for anomaly detection in real-world time series data."
      ],
      "metadata": {
        "id": "5_KIvkrWGEDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages"
      ],
      "metadata": {
        "id": "5Z_-YVv69kJF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4KCakefWv6p"
      },
      "outputs": [],
      "source": [
        "using Pkg\n",
        "Pkg.add([\"Flux\", \"ConformalPrediction\", \"DataFrames\", \"CSV\", \"Plots\", \"Statistics\", \"StatsPlots\", \"Random\", \"Measures\", \"RollingFunctions\", \"ShiftedArrays\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d81-ayqtV9_9"
      },
      "outputs": [],
      "source": [
        "using Flux, ConformalPrediction, DataFrames, CSV, Plots, Statistics, StatsPlots, Random, Dates, Measures, RollingFunctions, ShiftedArrays"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "aUcGiOdT-orz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUFn9bITZOUh"
      },
      "outputs": [],
      "source": [
        "data = CSV.read(\"/content/nyc_taxi.csv\", DataFrame)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVueWcgoqwve"
      },
      "outputs": [],
      "source": [
        "data[!, \"timestamp\"] = DateTime.(data[!, \"timestamp\"], dateformat\"yyyy-mm-dd HH:MM:SS.ssssss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8JF9yrvLrhSa"
      },
      "outputs": [],
      "source": [
        "anomalies_timestamp = [\n",
        "    \"2014-11-01 19:00:00.000000\",\n",
        "    \"2014-11-27 15:30:00.000000\",\n",
        "    \"2014-12-25 15:00:00.000000\",\n",
        "    \"2015-01-01 01:00:00.000000\",\n",
        "    \"2015-01-27 00:00:00.000000\"\n",
        "]\n",
        "anomaly_times = DateTime.(anomalies_timestamp, dateformat\"yyyy-mm-dd HH:MM:SS.ssssss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create a column for anomalies**"
      ],
      "metadata": {
        "id": "C2F3i5Eu-0Aj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0R9xp2Qvr6Zt"
      },
      "outputs": [],
      "source": [
        "data[!, \"is_anomaly\"] .= 0\n",
        "for each in anomaly_times\n",
        "    row_indices = findall(data[!, \"timestamp\"] .== each)\n",
        "    data[row_indices, \"is_anomaly\"] .= 1\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Description"
      ],
      "metadata": {
        "id": "ADeVxAc6-7Hg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nEWazDqr69j"
      },
      "outputs": [],
      "source": [
        "describe(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRdeugKusCbm"
      },
      "outputs": [],
      "source": [
        "println(\"Start time: \", minimum(data.timestamp))\n",
        "println(\"End time: \", maximum(data.timestamp))\n",
        "println(\"Time difference: \", maximum(data.timestamp) - minimum(data.timestamp))\n",
        "\n",
        "time_diff = maximum(data.timestamp) - minimum(data.timestamp)\n",
        "days_diff = time_diff.value / (1000 * 60 * 60 * 24)  # from ms to days\n",
        "println(\"Time difference: \", round(days_diff, digits=2), \" days\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Adding New Columns**"
      ],
      "metadata": {
        "id": "9ci5OZsAAGDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[!, :Weekday] = dayname.(data.timestamp)\n",
        "data[!, :Hour] = hour.(data.timestamp)\n",
        "data[!, :Day] = dayofweek.(data.timestamp)\n",
        "data[!, :Month] = month.(data.timestamp)\n",
        "data[!, :Year] = year.(data.timestamp)\n",
        "data[!, :Month_day] = day.(data.timestamp)"
      ],
      "metadata": {
        "id": "K4NU1S2eABNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualizing"
      ],
      "metadata": {
        "id": "N-ski79F_D7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NYC Taxi Passenger Count based on hourly, daily and weekly**"
      ],
      "metadata": {
        "id": "Z_g_ZrRI_gBV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rc2z5TFrrgBl"
      },
      "outputs": [],
      "source": [
        "# Resample timestamps\n",
        "data.hourly = DateTime.(floor.(data.timestamp, Dates.Hour))\n",
        "data.daily = DateTime.(floor.(data.timestamp, Dates.Day))\n",
        "data.weekly = DateTime.(floor.(data.timestamp, Dates.Week))\n",
        "\n",
        "# Aggregate means\n",
        "df_hour = combine(groupby(data, :hourly), :value => mean => :mean_value)\n",
        "df_day = combine(groupby(data, :daily), :value => mean => :mean_value)\n",
        "df_week = combine(groupby(data, :weekly), :value => mean => :mean_value)\n",
        "\n",
        "# Plot styling\n",
        "default(\n",
        "    yformatter = :plain,\n",
        "    legend = false,\n",
        "    grid = true,\n",
        "    gridcolor = :gray,\n",
        "    gridalpha = 0.5,\n",
        "    tickfontsize = 8,\n",
        "    guidefontsize = 10,\n",
        "    titlefontsize = 11,\n",
        "    linewidth = 1.5,\n",
        "    left_margin = 10mm\n",
        ")\n",
        "\n",
        "# Create subplots and assign it to a variable\n",
        "p = plot(\n",
        "    plot(df_hour.hourly, df_hour.mean_value, title=\"NYC Taxi Passengers (Hourly)\", xlabel=\"\", ylabel=\"Passenger Count\"),\n",
        "    plot(df_day.daily, df_day.mean_value, title=\"NYC Taxi Passengers (Daily)\", xlabel=\"\", ylabel=\"Passenger Count\"),\n",
        "    plot(df_week.weekly, df_week.mean_value, title=\"NYC Taxi Passengers (Weekly)\", xlabel=\"\", ylabel=\"Passenger Count\"),\n",
        "    layout = (3, 1),\n",
        "    size = (700, 1200)\n",
        ")\n",
        "\n",
        "# Save the plot\n",
        "#savefig(p, \"subplot.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Density Plot for Value Distribution**"
      ],
      "metadata": {
        "id": "OmEugDJm_qQI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xEY-swptKDo"
      },
      "outputs": [],
      "source": [
        "# Create a shaded density plot for 'value'\n",
        "density_plot = density(data.value,\n",
        "                       xformatter = :plain,\n",
        "                       title=\"Overall Value Distribution\",\n",
        "                       xlabel=\"Value\",\n",
        "                       ylabel=\"Density\",\n",
        "                       linewidth=2,\n",
        "                       fillrange=0.0,\n",
        "                       fillalpha=0.3)\n",
        "\n",
        "\n",
        "plot(density_plot, size=(700, 300), grid=true)\n",
        "# Save the plot\n",
        "#savefig(\"plot.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yCSc3HntpCL"
      },
      "outputs": [],
      "source": [
        "grouped = combine(groupby(data, :Weekday), :value => mean => :mean_value)\n",
        "\n",
        "# Plot the bar chart with increased space between the bars\n",
        "bar(grouped.Weekday, grouped.mean_value,\n",
        "    title=\"New York City Taxi Demand by Day\",\n",
        "    xlabel=\"Day of the Week\",\n",
        "    ylabel=\"Demand\",\n",
        "    legend=false,\n",
        "    grid=true,\n",
        "    width=0.4)  # Reduce the width to increase space between bars\n",
        "# Save the plot using the assigned variable 'p'\n",
        "#savefig(\"plot2.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**New York Taxi Demand by Hour**"
      ],
      "metadata": {
        "id": "_xITWwvUAuUs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q13wjQtcvckr"
      },
      "outputs": [],
      "source": [
        "grouped_hourly = combine(groupby(data, :Hour), :value => mean => :mean_value)\n",
        "\n",
        "# Plot the bar chart for hourly demand\n",
        "bar(grouped_hourly.Hour, grouped_hourly.mean_value,\n",
        "    title=\"New York City Taxi Demand by Hour\",\n",
        "    xlabel=\"Hour of the Day\",\n",
        "    ylabel=\"Demand\",\n",
        "    legend=false,\n",
        "    grid=true,\n",
        "    bar_width=0.3,\n",
        "    size=(700, 300))\n",
        "#savefig(\"plot1.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzPIcsJXvmLN"
      },
      "outputs": [],
      "source": [
        "grouped_hourly = combine(groupby(data, :Hour), :value => mean => :mean_value)\n",
        "\n",
        "# Plot the line chart for hourly demand\n",
        "plot(grouped_hourly.Hour, grouped_hourly.mean_value,\n",
        "     title=\"New York City Taxi Demand by Hour\",\n",
        "     xlabel=\"Hour of the Day\",\n",
        "     ylabel=\"Demand\",\n",
        "     label=\"Hourly Demand\",\n",
        "     linewidth=2,\n",
        "     grid=true,\n",
        "     size=(700, 300))\n",
        "#savefig(\"plot3.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**New York City Taxi Demand by Hour and Day**"
      ],
      "metadata": {
        "id": "KXhP0Wd7A9qt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj0J6SuHwHk2"
      },
      "outputs": [],
      "source": [
        "grouped = combine(groupby(data, [:Hour, :Weekday]), :value => mean => :mean_value)\n",
        "\n",
        "# Plot the line chart with each day of the week as a separate line\n",
        "p = plot(grouped.Hour, grouped.mean_value,\n",
        "    group=grouped.Weekday,\n",
        "    title=\"New York City Taxi Demand by Hour and Day\",\n",
        "    xlabel=\"Hour of the Day\",\n",
        "    ylabel=\"Average Demand\",\n",
        "    linewidth=2,\n",
        "    grid=true,\n",
        "    legend=:topright,\n",
        "    size=(700, 200))\n",
        "\n",
        "p = plot!(p, label=grouped.Weekday)\n",
        "\n",
        "display(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Anomalies Visualisation**"
      ],
      "metadata": {
        "id": "hZrYzo7bBPSy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrITCHGIwNG_"
      },
      "outputs": [],
      "source": [
        "date_ticks = data.timestamp[1:floor(Int, length(data.timestamp)/8):end]\n",
        "date_ticks = date_ticks[1:8]\n",
        "\n",
        "date_labels = Dates.format.(date_ticks, \"mmm yyyy\")\n",
        "\n",
        "plot(data.timestamp, data.value,\n",
        "    label=\"Taxi Demand\",\n",
        "    linewidth=1.5,\n",
        "    color=:blue,\n",
        "    xticks=(date_ticks, date_labels),\n",
        "    xrotation=45,\n",
        "    xlabel=\"Date\",\n",
        "    ylabel=\"Passenger Count\",\n",
        "    title=\"NYC Taxi Demand\",\n",
        "    legend=:topleft,\n",
        "    size=(800,400))\n",
        "\n",
        "scatter!(data.timestamp[data.is_anomaly .== 1], data.value[data.is_anomaly .== 1],\n",
        "    label=\"Anomalies\",\n",
        "    color=:red,\n",
        "    markersize=5)\n",
        "\n",
        "plot!(grid=true, gridalpha=0.3)\n",
        "#savefig(\"plot5.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plkdNvrkJrr0"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalised the dataset**"
      ],
      "metadata": {
        "id": "rCDtaoYwBl2I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVMmgFZfKgZw"
      },
      "outputs": [],
      "source": [
        "X = data[!, :value]\n",
        "X_normalized = (X .- mean(X)) ./ std(X)\n",
        "y = data.is_anomaly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split Dataset**"
      ],
      "metadata": {
        "id": "IhfxXxNzBrmA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jdu1062nqY8g"
      },
      "outputs": [],
      "source": [
        "n = length(X_normalized)\n",
        "n_train = floor(Int, 0.7n)\n",
        "\n",
        "X_train = X_normalized[1:n_train]\n",
        "y_train = y[1:n_train]\n",
        "\n",
        "X_test = X_normalized[n_train+1:end]\n",
        "y_test = y[n_train+1:end]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Sequences**"
      ],
      "metadata": {
        "id": "1ccsOG7FBw_y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcYXntE4K20p"
      },
      "outputs": [],
      "source": [
        "window_size = 24\n",
        "function create_sequences(data, window_size)\n",
        "    sequences = []\n",
        "    for i in 1:length(data)-window_size\n",
        "        push!(sequences, data[i:i+window_size-1])\n",
        "    end\n",
        "    return sequences\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj1Sn4dZKn_6"
      },
      "outputs": [],
      "source": [
        "X_train_seq = create_sequences(X_train, window_size)\n",
        "X_test_seq = create_sequences(X_test, window_size)\n",
        "\n",
        "X_train_flux = [reshape(x, 1, window_size, 1) for x in X_train_seq]\n",
        "X_test_flux = [reshape(x, 1, window_size, 1) for x in X_test_seq]\n",
        "\n",
        "y_train_seq = y_train[window_size+1:end]\n",
        "y_test_seq = y_test[window_size+1:end]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzMRLSTCKsN5"
      },
      "outputs": [],
      "source": [
        "y_train_seq = y_train[window_size+1:end]\n",
        "y_test_seq = y_test[window_size+1:end]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM Model**"
      ],
      "metadata": {
        "id": "HIOtMCbPB9QQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85WDFAXrK9NI",
        "outputId": "8c0da5cf-2fe8-477f-adcc-366d1513a817"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Chain(\n",
              "  LSTM(1 => 32),                        \u001b[90m# 4_352 parameters\u001b[39m\n",
              "  Dropout(0.1),\n",
              "  LSTM(32 => 16),                       \u001b[90m# 3_136 parameters\u001b[39m\n",
              "  Dense(16 => 1, σ),                    \u001b[90m# 17 parameters\u001b[39m\n",
              ") \u001b[90m                  # Total: 8 arrays, \u001b[39m7_505 parameters, 29.895 KiB."
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model = Chain(\n",
        "    LSTM(1 => 32),\n",
        "    Dropout(0.1),\n",
        "    LSTM(32 => 16),\n",
        "    Dense(16 => 1, sigmoid)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weighted Loss Function**"
      ],
      "metadata": {
        "id": "Q_WwXykJCDZK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dnjc0xQuLBUd"
      },
      "outputs": [],
      "source": [
        "function weighted_loss(y_pred, y_true; weight_anomaly=200.0f0)\n",
        "    ϵ = eps(Float32)\n",
        "    -mean(weight_anomaly * y_true .* log.(y_pred .+ ϵ) .+\n",
        "          (1 .- y_true) .* log.(1 .- y_pred .+ ϵ))\n",
        "end\n",
        "\n",
        "\n",
        "function loss(m, x, y)\n",
        "    y_pred = m(x)\n",
        "    weighted_loss(y_pred, Float32(y))\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiQDAfKwLE-0"
      },
      "outputs": [],
      "source": [
        "X_train_float = [Float32.(x) for x in X_train_flux]\n",
        "y_train_float = Float32.(y_train_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimiser**"
      ],
      "metadata": {
        "id": "EuMhAqn6CMnn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ln6ZLJ3PLIqP"
      },
      "outputs": [],
      "source": [
        "opt_state = Flux.setup(Adam(0.001), model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training**"
      ],
      "metadata": {
        "id": "Nel3yYF4CRrA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrg3PtV3LTG0",
        "outputId": "93c84bd8-cccc-40a7-a8cf-65c6dd48796e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 0.6552 | Accuracy = 99.9722%\n",
            "Epoch 2: Loss = 0.4111 | Accuracy = 99.9722%\n",
            "Epoch 3: Loss = 0.2561 | Accuracy = 99.9722%\n",
            "Epoch 4: Loss = 0.2346 | Accuracy = 99.9722%\n",
            "Epoch 5: Loss = 0.2184 | Accuracy = 99.9722%\n",
            "Epoch 6: Loss = 0.2117 | Accuracy = 99.9722%\n",
            "Epoch 7: Loss = 0.2147 | Accuracy = 99.9722%\n",
            "Epoch 8: Loss = 0.2067 | Accuracy = 99.9722%\n",
            "Epoch 9: Loss = 0.2202 | Accuracy = 99.9722%\n",
            "Epoch 10: Loss = 0.192 | Accuracy = 99.9722%\n"
          ]
        }
      ],
      "source": [
        "using Flux.Optimise: train!\n",
        "epochs = 10\n",
        "for epoch in 1:epochs\n",
        "    Flux.train!(loss, model, zip(X_train_float, y_train_float), opt_state)\n",
        "\n",
        "    train_pred = [Flux.flatten(model(x))[1] for x in X_train_float]\n",
        "    current_loss = mean([loss(model, x, y) for (x, y) in zip(X_train_float, y_train_float)])\n",
        "    current_acc = mean(round.(train_pred) .== y_train_float) * 100\n",
        "\n",
        "    println(\"Epoch $epoch: Loss = \", round(current_loss, digits=4),\n",
        "            \" | Accuracy = \", round(current_acc, digits=4), \"%\")\n",
        "end"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**"
      ],
      "metadata": {
        "id": "KAKGV8CCCYGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnZ0Kbmyv2T8"
      },
      "outputs": [],
      "source": [
        "function evaluate(model, X_test, y_test)\n",
        "    predictions = [model(x) for x in X_test]\n",
        "\n",
        "    predictions = [Flux.flatten(pred)[1] for pred in predictions]\n",
        "    predictions = [pred > 0.5 ? 1 : 0 for pred in predictions]\n",
        "\n",
        "    accuracy = sum(predictions .== y_test) / length(y_test)\n",
        "    return accuracy\n",
        "end\n",
        "\n",
        "# Evaluate on test data\n",
        "accuracy = evaluate(model, X_test_flux, y_test_seq)\n",
        "println(\"Test Accuracy: \", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5eF7DTKqiy1"
      },
      "outputs": [],
      "source": [
        "X_train_float = [Float32.(x) for x in X_train_flux]\n",
        "y_train_float = Float32.(y_train_seq)\n",
        "\n",
        "X_test_float = [Float32.(x) for x in X_test_flux]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "h0Z1590GC1KX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgIvwJOOqlPr"
      },
      "outputs": [],
      "source": [
        " threshold = 0.03\n",
        "test_preds = [Flux.flatten(model(x))[1] for x in X_test_float]\n",
        "test_binary = map(p -> p > threshold ? 1 : 0, test_preds)\n",
        "\n",
        "TP = sum((y_test_seq .== 1) .& (test_binary .== 1))\n",
        "FP = sum((y_test_seq .== 0) .& (test_binary .== 1))\n",
        "FN = sum((y_test_seq .== 1) .& (test_binary .== 0))\n",
        "TN = sum((y_test_seq .== 0) .& (test_binary .== 0))\n",
        "\n",
        "println(\"True Positive: $TP,\n",
        " False Positive: $FP,\n",
        " False Negative: $FN,\n",
        " True Negative: $TN\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMbNEMf2yFtC"
      },
      "outputs": [],
      "source": [
        "TP = 2\n",
        "FP = 1284\n",
        "FN = 1\n",
        "TN = 1786\n",
        "\n",
        "# Calculate precision, accuracy, recall and f1-score\n",
        "precision = TP / (TP + FP)\n",
        "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
        "recall = TP / (TP + FN) # Calculate recall\n",
        "my_f1score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "# Print the calculated metrics\n",
        "println(\"Precision: $precision\")\n",
        "println(\"Accuracy: $accuracy\")\n",
        "println(\"Recall: $recall\") # Print recall\n",
        "println(\"F1-score: $my_f1score\") # Print F1-score\n",
        "\n",
        "# Plotting\n",
        "labels = [\"TP\", \"FP\", \"FN\", \"TN\"]\n",
        "values = [TP, FP, FN, TN]\n",
        "\n",
        "# Create the confusion matrix plot\n",
        "p1 = bar(labels, values, color=[\"green\", \"red\", \"orange\", \"blue\"],\n",
        "         title=\"Confusion Matrix\", ylabel=\"Count\", xlabel=\"Categories\")\n",
        "\n",
        "# Plot Precision and Accuracy\n",
        "p2 = bar([\"Precision\", \"Accuracy\", \"Recall\", \"F1-score\"], [precision, accuracy, recall, my_f1score], color=[\"blue\", \"green\", \"orange\", \"red\"],\n",
        "         title=\"Metrics\", ylabel=\"Score\")\n",
        "\n",
        "# Show the plots\n",
        "plot(p1, p2, layout=(1, 2))\n",
        "#savefig(\"plot4.png\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oguvr9Hw9evS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}